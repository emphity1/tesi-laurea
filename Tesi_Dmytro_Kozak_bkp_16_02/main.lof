\babel@toc {italian}{}\relax 
\babel@toc {italian}{}\relax 
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\contentsline {figure}{\numberline {2.1}{\ignorespaces Esempi di Immagini dal Dataset CIFAR-10. La bassa risoluzione ($32 \times 32$) rende il compito di classificazione sfidante anche per l'occhio umano, specialmente per classi visivamente simili.\relax }}{7}{figure.2.1}%
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\contentsline {figure}{\numberline {6.1}{\ignorespaces Architettura MobileNetECARep. I blocchi azzurri rappresentano i tensori intermedi. Il dettaglio mostra il modulo RepInvertedResidual con integrazione di Efficient Channel Attention (ECA) e la struttura di convoluzione riparametrizzabile (RepConv).\relax }}{22}{figure.6.1}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces Schema del blocco Inverted Residual modificato con integrazione del modulo ECA dopo la Depthwise Convolution.\relax }}{24}{figure.6.2}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces Confronto tra ReLU (rossa) e GELU (blu). La natura liscia e non monotona della GELU vicino allo zero favorisce un flusso dei gradienti più robusto.\relax }}{25}{figure.6.3}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces Confronto Standard Convolution vs Depthwise Separable (usata in MobileNet). La re-parametrizzazione ci permette di usare strutture complesse in training che collassano in efficienti depthwise/standard conv all'inferenza.\relax }}{26}{figure.6.4}%
\contentsline {figure}{\numberline {6.5}{\ignorespaces Andamento del Learning Rate durante le 200 epoche di training (Cosine Annealing). Il tasso di apprendimento decresce dolcemente seguendo una curva cosinusoidale.\relax }}{29}{figure.6.5}%
\addvspace {10pt}
\contentsline {figure}{\numberline {7.1}{\ignorespaces Dinamiche di apprendimento per le diverse configurazioni. Si noti come la configurazione finale (rossa) converga a un'accuratezza superiore nonostante una loss iniziale più alta dovuta alla difficoltà introdotta dall'augmentation.\relax }}{32}{figure.7.1}%
\contentsline {figure}{\numberline {7.2}{\ignorespaces Matrice di Confusione del modello MobileNetECA-Rep sul Test Set.\relax }}{33}{figure.7.2}%
\contentsline {figure}{\numberline {7.3}{\ignorespaces Dettaglio delle curve ROC per le 10 classi (Zoom TPR 0.8-1.0). L'area sotto la curva (AUC) è prossima a 1.0 per tutte le classi, indicando un'eccellente separabilità.\relax }}{34}{figure.7.3}%
\contentsline {figure}{\numberline {7.4}{\ignorespaces Esempi di errata classificazione (Test Set). Ogni riquadro mostra l'immagine originale con l'etichetta vera (True), quella predetta (Pred) e la confidenza del modello. Si noti come alcune immagini siano ambigue o difficili anche per un osservatore umano.\relax }}{35}{figure.7.4}%
\contentsline {figure}{\numberline {7.5}{\ignorespaces Efficiency Frontier: Accuratezza vs Numero di Parametri (scala logaritmica). Il nostro modello (stella rossa) si trova nettamente a sinistra (meno parametri) rispetto a modelli con accuratezza simile come ResNet-32 o VGG-16.\relax }}{37}{figure.7.5}%
\contentsline {figure}{\numberline {7.6}{\ignorespaces Heatmap dell'accuratezza (Validation Accuracy) al variare di Learning Rate e Weight Decay. Si osserva che alti valori di LR richiedono un decay maggiore per stabilizzare l'addestramento.\relax }}{39}{figure.7.6}%
\contentsline {figure}{\numberline {7.7}{\ignorespaces Accuratezza in funzione di Learning Rate e Width Multiplier. Reti più larghe (Width > 0.5) beneficiano di LR più alti, mentre reti molto sottili richiedono un approccio più conservativo.\relax }}{40}{figure.7.7}%
\contentsline {figure}{\numberline {7.8}{\ignorespaces Interazione tra Width Multiplier e Weight Decay. Reti più piccole sono meno soggette a overfitting massiccio ma beneficiano comunque di una moderata regolarizzazione.\relax }}{41}{figure.7.8}%
\addvspace {10pt}
\addvspace {10pt}
