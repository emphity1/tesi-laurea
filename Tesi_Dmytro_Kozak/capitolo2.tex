
Questo capitolo descrive nel dettaglio il dataset CIFAR-10, utilizzato per l'addestramento e la valutazione dei modelli di classificazione implementati. CIFAR-10 rappresenta uno standard de facto per la valutazione di modelli di Computer Vision su piccola scala.

\section{Descrizione del Dataset CIFAR-10}
Il dataset CIFAR-10 (Canadian Institute for Advanced Research, 10 classes) è una raccolta di 60.000 immagini a colori di dimensione $32 \times 32$ pixel, suddivise in 10 classi distinte, con 6.000 immagini per classe \cite{krizhevsky2009learning}.
Le 10 classi rappresentano oggetti e categorie comuni:
\begin{enumerate}
    \item \textbf{Aereo} (Airplane)
    \item \textbf{Automobile} (Automobile)
    \item \textbf{Uccello} (Bird)
    \item \textbf{Gatto} (Cat)
    \item \textbf{Cervo} (Deer)
    \item \textbf{Cane} (Dog)
    \item \textbf{Rana} (Frog)
    \item \textbf{Cavallo} (Horse)
    \item \textbf{Nave} (Ship)
    \item \textbf{Camion} (Truck)
\end{enumerate}

Le classi sono mutuamente esclusive: non c'è sovrapposizione tra automobili e camion. Il dataset è bilanciato, il che semplifica l'analisi delle metriche (l'accuratezza è una buona stima delle prestazioni globali).

\subsection{Struttura e Organizzazione dei Dati}
Il dataset è suddiviso in due sottoinsiemi principali:
\begin{itemize}
    \item \textbf{Training Set}: Composto da 50.000 immagini (5.000 per classe), utilizzato esclusivamente per l'aggiornamento dei pesi del modello.
    \item \textbf{Test Set}: Composto da 10.000 immagini (1.000 per classe), utilizzato per valutare le prestazioni finali su dati non visti.
\end{itemize}

Ogni immagine è rappresentata come un tensore di dimensioni $3 \times 32 \times 32$ (Canali, Altezza, Larghezza). I valori dei pixel sono interi nell'intervallo $[0, 255]$.
La bassa risoluzione ($32 \times 32$) rende il compito di classificazione difficile per l'occhio umano in alcuni casi (ambiguità), ma ideale per testare l'efficienza di architetture leggere.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figure/cifar10_images.png}
    \caption{Esempi di Immagini dal Dataset CIFAR-10. La bassa risoluzione ($32 \times 32$) rende il compito di classificazione sfidante anche per l'occhio umano, specialmente per classi visivamente simili.}
    \label{fig:cifar10_sample}
\end{figure}

\section{Preprocessing dei Dati}
Prima di essere utilizzate per l'addestramento, le immagini subiscono una serie di trasformazioni per facilitare la convergenza della rete.

\subsection{Normalizzazione}
I valori dei pixel $[0, 255]$ vengono scalati nell'intervallo $[0, 1]$ dividendo per 255. Successivamente, si applica una standardizzazione basata sulle statistiche del dataset CIFAR-10:
$$ x_{norm} = \frac{x - \mu}{\sigma} $$
dove $\mu = (0.4914, 0.4822, 0.4465)$ sono le medie dei canali RGB e $\sigma = (0.2023, 0.1994, 0.2010)$ le deviazioni standard.
Questa operazione centra i dati intorno allo zero, migliorando la stabilità numerica e la velocità di addestramento.

\subsection{Data Augmentation Standard}
Per migliorare la capacità di generalizzazione del modello e prevenire l'overfitting, vengono applicate trasformazioni randomiche alle immagini del training set. Le tecniche standard includono:
\begin{itemize}
    \item \textbf{Random Horizontal Flip}: L'immagine viene ribaltata orizzontalmente con probabilità $p=0.5$. Questo insegna alla rete che l'orientamento (es. un'auto rivolta verso sinistra o destra) non cambia la classe dell'oggetto.
    \item \textbf{Random Crop}: Viene applicato un padding di 4 pixel (riflettendo i bordi) portando l'immagine a $40 \times 40$, da cui viene estratto un ritaglio casuale $32 \times 32$. Questo introduce invarianza alle piccole traslazioni.
\end{itemize}

Oltre a queste, nel Capitolo \ref{capitolo5} discuteremo l'uso di tecniche avanzate come \textit{Cutout} e \textit{AutoAugment}, cruciali per le prestazioni del nostro modello.

\section{Sfide e Limitazioni}
Lavorare con immagini a bassa risoluzione ($32 \times 32$) presenta sfide uniche rispetto a dataset ad alta risoluzione come ImageNet ($224 \times 224$):
\begin{itemize}
    \item \textbf{Perdita di Dettaglio}: Molti oggetti sono riconoscibili solo dal contesto o dalla forma globale, poiché i dettagli fini (es. la trama del pelo di un animale o il modello di un'auto) sono persi nella pixelatura.
    \item \textbf{Ambiguità Inter-classe}: Alcune classi, come \textit{Automobile} e \textit{Camion}, o \textit{Cane} e \textit{Gatto}, possono apparire molto simili a questa risoluzione, specialmente in presenza di occlusioni o pose insolite.
    \item \textbf{Background Clutter}: In immagini così piccole, lo sfondo può occupare una porzione significativa dell'immagine, confondendo la rete se non dispone di meccanismi di attenzione efficaci.
\end{itemize}
Queste difficoltà motivano la necessità di architetture specializzate capaci di estrarre il massimo contenuto informativo da pochi pixel disponibili.
