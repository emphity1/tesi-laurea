\begin{thebibliography}{10}

\bibitem{krizhevsky2009learning}
A.~Krizhevsky and G.~Hinton, ``Learning multiple layers of features from tiny
  images,'' tech. rep., Citeseer, 2009.

\bibitem{hendrycks2016gaussian}
D.~Hendrycks and K.~Gimpel, ``Gaussian error linear units (gelus),'' {\em arXiv
  preprint arXiv:1606.08415}, 2016.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in {\em Proceedings of the IEEE conference on computer vision
  and pattern recognition}, pp.~770--778, 2016.

\bibitem{howard2017mobilenets}
A.~G. Howard, M.~Zhu, B.~Chen, D.~Kalenichenko, W.~Wang, T.~Weyand,
  M.~Andreetto, and H.~Adam, ``Mobilenets: Efficient convolutional neural
  networks for mobile vision applications,'' {\em arXiv preprint
  arXiv:1704.04861}, 2017.

\bibitem{sandler2018mobilenetv2}
M.~Sandler, A.~Howard, M.~Zhu, A.~Zhmoginov, and L.-C. Chen, ``Mobilenetv2:
  Inverted residuals and linear bottlenecks,'' in {\em Proceedings of the IEEE
  conference on computer vision and pattern recognition}, pp.~4510--4520, 2018.

\bibitem{hu2018squeeze}
J.~Hu, L.~Shen, and G.~Sun, ``Squeeze-and-excitation networks,'' in {\em
  Proceedings of the IEEE conference on computer vision and pattern
  recognition}, pp.~7132--7141, 2018.

\bibitem{wang2020eca}
Q.~Wang, B.~Wu, P.~Zhu, P.~Li, W.~Zuo, and Q.~Hu, ``Eca-net: Efficient channel
  attention for deep convolutional neural networks,'' in {\em Proceedings of
  the IEEE/CVF conference on computer vision and pattern recognition},
  pp.~11534--11542, 2020.

\bibitem{ding2021repvgg}
X.~Ding, X.~Zhang, N.~Ma, J.~Han, G.~Ding, and J.~Sun, ``Repvgg: Making
  vgg-style convnets great again,'' in {\em Proceedings of the IEEE/CVF
  conference on computer vision and pattern recognition}, pp.~13733--13742,
  2021.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' in {\em International Conference on Learning
  Representations (ICLR)}, 2015.

\bibitem{ma2018shufflenet}
N.~Ma, X.~Zhang, H.-T. Zheng, and J.~Sun, ``Shufflenet v2: Practical guidelines
  for efficient cnn architecture design,'' in {\em Proceedings of the European
  conference on computer vision (ECCV)}, pp.~116--131, 2018.

\bibitem{goodfellow2016deep}
I.~Goodfellow, Y.~Bengio, and A.~Courville, {\em Deep learning}.
\newblock MIT press, 2016.

\bibitem{lecun2015deep}
Y.~LeCun, Y.~Bengio, and G.~Hinton, ``Deep learning,'' {\em nature}, vol.~521,
  no.~7553, pp.~436--444, 2015.

\bibitem{cubuk2019autoaugment}
E.~D. Cubuk, B.~Zoph, D.~Mane, V.~Vasudevan, and Q.~V. Le, ``Autoaugment:
  Learning augmentation strategies from data,'' in {\em Proceedings of the
  IEEE/CVF conference on computer vision and pattern recognition},
  pp.~113--123, 2019.

\bibitem{zhong2020random}
Z.~Zhong, L.~Zheng, G.~Kang, S.~Li, and Y.~Yang, ``Random erasing data
  augmentation,'' {\em Huazhong University of Science and Technology},
  vol.~200, 2020.

\end{thebibliography}
