% !TeX spellcheck = it_IT
\section{Grid Search Sistematica}

\subsection{Obiettivo}
L'ottimizzazione degli iperparametri è cruciale per ottenere le migliori prestazioni da un'architettura neurale. Invece di procedere per tentativi empirici non sistematici, è stata condotta una \textbf{grid search esaustiva} per esplorare lo spazio dei parametri in modo riproduc

ibile.

\subsection{Spazio di Ricerca}
I parametri esplorati sono:

\begin{itemize}
    \item \textbf{Learning Rate}: $\eta \in \{0.005, 0.01, 0.025, 0.05, 0.075, 0.1\}$ (6 valori)
    \item \textbf{Width Multiplier}: $\alpha \in \{0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6\}$ (7 valori)
    \item \textbf{Weight Decay}: $\lambda \in \{10^{-4}, 2 \times 10^{-4}, 3 \times 10^{-4}, 5 \times 10^{-4}, 10^{-3}\}$ (5 valori)
\end{itemize}

\textbf{Parametri fissi}:
\begin{itemize}
    \item Batch size: 128
    \item Momentum: 0.9
    \item LR scale: 1.54
\end{itemize}

\textbf{Combinazioni totali}: $6 \times 7 \times 5 = 210$ configurazioni

\subsection{Strategia: Two-Phase Approach}
Per ridurre il tempo computazionale senza sacrificare la qualità della ricerca:

\textbf{Fase 1 - Screening (25 epoche)}:
\begin{itemize}
    \item Tutte le 210 configurazioni allenate per 25 epoche
    \item Valutazione multi-checkpoint (epoch 15, 20, 25)
    \item Early stopping: configurazioni con val\_acc < 80\% @ epoch 15 sono scartate
    \item Calcolo di uno \textit{score predittivo} basato su accuracy corrente + trend di miglioramento
\end{itemize}

\textbf{Fase 2 - Refinement (50 epoche)}:
\begin{itemize}
    \item Top-5 configurazioni per score allenate per 50 epoche complete
    \item Salvataggio best model e metriche dettagliate
    \item Identificazione della configurazione ottimale finale
\end{itemize}

\textbf{Tempo totale stimato}: ~2-3 ore su GPU (vs ~8-10 ore per 210×50 epoche)

\subsection{Scoring Function}
Lo score predittivo combina accuracy corrente e trend:

\begin{equation}
\text{score} = 0.7 \cdot \text{val\_acc}_{\text{epoch 25}} + 0.3 \cdot \text{val\_acc}_{\text{predicted}}
\end{equation}

dove:
\begin{equation}
\text{val\_acc}_{\text{predicted}} = \text{val\_acc}_{\text{epoch 25}} + \overline{r} \cdot 25
\end{equation}

\begin{equation}
\overline{r} = \frac{1}{N-1}\sum_{i=1}^{N-1} \frac{\text{val\_acc}_{e_{i+1}} - \text{val\_acc}_{e_i}}{e_{i+1} - e_i}
\end{equation}

$\overline{r}$ = tasso medio di miglioramento per epoca tra checkpoint $e_i \in \{15, 20, 25\}$.

\section{Implementazione Grid Search}

\subsection{Codice e Workflow}
Script principale: \texttt{src/scripts/grid\_search\_ultra\_fast.py}

\textbf{Processo}:
\begin{enumerate}
    \item Generazione combinazioni con \texttt{itertools.product}
    \item Pre-caricamento dataset CIFAR-10 (condiviso tra run)
    \item Per ogni configurazione:
    \begin{itemize}
        \item Inizializza modello, optimizer, scheduler
        \item Training loop 25 epoche
        \item Valutazione checkpoint, calcolo score
        \item Early stopping se necessario
    \end{itemize}
    \item Sorting per score, selezione top-5
    \item Refinement con training completo 50 epoche
    \item Salvataggio risultati JSON e summary
\end{enumerate}

\subsection{Output e Artifact}
Struttura directory risultati:
\begin{verbatim}
reports/grid_search_ultra_fast/search_YYYYMMDD_HHMMSS/
|-- SUMMARY.txt
|-- two_phase_results.json
|-- best_config.json
|-- phase1_screening/
|   |-- screen_001_.../logs/screening_metrics.json
|   |-- screen_002_.../logs/...
|   `-- ...
`-- phase2_refinement/
    |-- refine_01_.../
    |   |-- logs/final_metrics.json
    |   `-- models/best_model.pth
    `-- ...
\end{verbatim}

\section{Risultati Grid Search}

\subsection{Statistiche e Esecuzione}
\begin{itemize}
    \item \textbf{Configurazioni Completate}: 27 (Grid search esaustiva su spazio ridotto: 3 LR $\times$ 3 Width $\times$ 3 WD)
    \item \textbf{Tempo medio per run}: \textasciitilde 7 minuti (su GPU)
    \item \textbf{Strategia adottata}: Esecuzione completa di tutte le 27 configurazioni per 50 epoche ciascuna, per garantire la robustezza dei risultati statistici.
\end{itemize}

\subsection{Top-5 Configurazioni}
La Tabella~\ref{tab:top5} mostra le migliori configurazioni identificate.

\begin{table}[h]
\centering
\caption{Top-5 configurazioni da grid search (ordinate per Validation Accuracy)}
\label{tab:top5}
\begin{tabular}{cccccc}
\toprule
\textbf{Rank} & \textbf{Val Acc (\%)} & \textbf{LR} & \textbf{Width} & \textbf{WD} & \textbf{Run ID} \\
\midrule
1 & 91.47\% & 0.05 & 0.5 & 5e-4 & 27 \\
2 & 91.31\% & 0.025 & 0.5 & 5e-4 & 18 \\
3 & 90.73\% & 0.05 & 0.5 & 3e-4 & 26 \\
4 & 90.62\% & 0.05 & 0.42 & 5e-4 & 24 \\
5 & 90.11\% & 0.025 & 0.5 & 3e-4 & 17 \\
\bottomrule
\end{tabular}
\end{table}

I risultati confermano che una larghezza maggiore (\texttt{width\_mult=0.5}) e un weight decay più aggressivo (\texttt{5e-4}) favoriscono le prestazioni migliori, suggerendo che il modello beneficia di una maggiore capacità regolarizzata.

\subsection{Analisi Insights Visuale}
Le heatmaps seguenti illustrano l'impatto combinato degli iperparametri sull'accuratezza di validazione.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \includegraphics[width=\linewidth]{figure/heatmap_lr_width.png}
        \caption{LR vs Width Multiplier}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
        \includegraphics[width=\linewidth]{figure/heatmap_width_wd.png}
        \caption{Width Multiplier vs Weight Decay}
    \end{subfigure}
    \caption{Heatmaps dei risultati della Grid Search: si nota una chiara preferenza per width multiplier più alti (0.5), mentre il learning rate di 0.05 sembra offrire il miglior trade-off convergenza/stabilità.}
    \label{fig:heatmaps}
\end{figure}

\section{Training Finale (200 Epoche)}

\subsection{Configurazione Scelta}
Basandosi sui risultati del grid search (Run ID 27), la configurazione ottimale identificata è:

\begin{itemize}
    \item \textbf{Learning rate}: 0.05
    \item \textbf{Width multiplier}: 0.5
    \item \textbf{Weight decay}: 5e-4
    \item \textbf{Momentum}: 0.9
    \item \textbf{Epoche}: 200 (estese per massimizzare la convergenza)
\end{itemize}

\subsection{Dinamica dell'Apprendimento}
Il training prolungato ha permesso di raffinare ulteriormente i pesi, portando l'accuratezza finale dal \textasciitilde 91.5\% (50 epoche) al \textbf{92.47\%} (200 epoche).

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\textwidth]{figure/accuracy_curve_200.png}
    \caption{Curve di Accuracy (Training vs Validation) durante le 200 epoche. Si osserva una crescita costante, con il validation che segue il training senza eccessivo overfitting, grazie al weight decay ottimizzato.}
    \label{fig:acc_curve_200}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\textwidth]{figure/lr_schedule_200.png}
    \caption{Profilo del Learning Rate (Cosine Annealing). La riduzione progressiva del tasso di apprendimento permette al modello di uscire dai minimi locali nelle fasi iniziali e di convergere dolcemente verso un ottimo globale nelle fasi finali.}
    \label{fig:lr_schedule}
\end{figure}

\section{Validazione e Testing Approfonditi}

\subsection{Metriche per Classe}
Oltre all'accuratezza globale, è fondamentale analizzare le prestazioni su singole categorie. La Figura~\ref{fig:class_perf} mostra l'F1-Score per ciascuna delle 10 classi.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figure/per_class_f1_bars.png}
    \caption{F1-Score per classe. Il modello eccelle su classi distintive come "Automobile" e "Nave", mentre mostra (come atteso) lievi difficoltà maggiori su classi animali simili come "Gatto" e "Cane", pur mantenendo score > 0.84.}
    \label{fig:class_perf}
\end{figure}

\subsection{Matrice di Confusione e ROC}
Per i dettagli sugli errori di classificazione e le curve ROC, si rimanda al Capitolo~\ref{chap:risultati}.